{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9ff5f3",
   "metadata": {},
   "source": [
    "Krista Miller \n",
    "Data Mining Assignment 1, part 2\n",
    "\n",
    "Association Rules were originally created for mining information for market baskets.  But, they can provide insight into other applications also.  In this part of the assignment you will use the mlxtend library functions apriori( ) and association_rules( ) to explore text data.  Specifically, we will look at the text from three books:\n",
    "\n",
    "Sense and Sensibility, by Jane Austin, published 1811\n",
    "\n",
    "A Tale of Two Cities, by Charles Dickens, published 1859\n",
    "\n",
    "On The Origin of Species, by Charles Darwin, published 1859 (although written over a 20 year period preceding that date).\n",
    "\n",
    "All three books were written in english by english people at \"roughly\" the same time, hence one could assume some commonality in writing style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18244e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "201425c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family</td>\n",
       "      <td>of</td>\n",
       "      <td>dashwood</td>\n",
       "      <td>had</td>\n",
       "      <td>long</td>\n",
       "      <td>been</td>\n",
       "      <td>settled</td>\n",
       "      <td>insussex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>their</td>\n",
       "      <td>estate</td>\n",
       "      <td>was</td>\n",
       "      <td>large</td>\n",
       "      <td>and</td>\n",
       "      <td>their</td>\n",
       "      <td>residence</td>\n",
       "      <td>was</td>\n",
       "      <td>at</td>\n",
       "      <td>norland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>park</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>centre</td>\n",
       "      <td>of</td>\n",
       "      <td>their</td>\n",
       "      <td>property</td>\n",
       "      <td>where</td>\n",
       "      <td>for</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>generations</td>\n",
       "      <td>they</td>\n",
       "      <td>had</td>\n",
       "      <td>lived</td>\n",
       "      <td>in</td>\n",
       "      <td>so</td>\n",
       "      <td>respectable</td>\n",
       "      <td>a</td>\n",
       "      <td>manner</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>engage</td>\n",
       "      <td>the</td>\n",
       "      <td>general</td>\n",
       "      <td>good</td>\n",
       "      <td>opinion</td>\n",
       "      <td>of</td>\n",
       "      <td>their</td>\n",
       "      <td>surroundingacquaintance</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14454</th>\n",
       "      <td>and</td>\n",
       "      <td>the</td>\n",
       "      <td>happiness</td>\n",
       "      <td>of</td>\n",
       "      <td>elinor</td>\n",
       "      <td>and</td>\n",
       "      <td>marianne</td>\n",
       "      <td>let</td>\n",
       "      <td>it</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14455</th>\n",
       "      <td>be</td>\n",
       "      <td>ranked</td>\n",
       "      <td>as</td>\n",
       "      <td>the</td>\n",
       "      <td>least</td>\n",
       "      <td>considerable</td>\n",
       "      <td>that</td>\n",
       "      <td>though</td>\n",
       "      <td>sisters</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14456</th>\n",
       "      <td>living</td>\n",
       "      <td>almost</td>\n",
       "      <td>within</td>\n",
       "      <td>sight</td>\n",
       "      <td>of</td>\n",
       "      <td>each</td>\n",
       "      <td>other</td>\n",
       "      <td>they</td>\n",
       "      <td>could</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14457</th>\n",
       "      <td>without</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>between</td>\n",
       "      <td>themselves</td>\n",
       "      <td>or</td>\n",
       "      <td>producing</td>\n",
       "      <td>coolness</td>\n",
       "      <td>between</td>\n",
       "      <td>theirhusbands</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14458</th>\n",
       "      <td>the</td>\n",
       "      <td>end</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14459 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1          2           3       4             5  \\\n",
       "0           family            of   dashwood         had    long          been   \n",
       "1            their        estate        was       large     and         their   \n",
       "2             park            in        the      centre      of         their   \n",
       "3      generations          they        had       lived      in            so   \n",
       "4               to        engage        the     general    good       opinion   \n",
       "...            ...           ...        ...         ...     ...           ...   \n",
       "14454          and           the  happiness          of  elinor           and   \n",
       "14455           be        ranked         as         the   least  considerable   \n",
       "14456       living        almost     within       sight      of          each   \n",
       "14457      without  disagreement    between  themselves      or     producing   \n",
       "14458          the           end        NaN         NaN     NaN           NaN   \n",
       "\n",
       "                 6         7                        8        9  \n",
       "0          settled  insussex                      NaN      NaN  \n",
       "1        residence       was                       at  norland  \n",
       "2         property     where                      for     many  \n",
       "3      respectable         a                   manner       as  \n",
       "4               of     their  surroundingacquaintance      NaN  \n",
       "...            ...       ...                      ...      ...  \n",
       "14454     marianne       let                       it      not  \n",
       "14455         that    though                  sisters      and  \n",
       "14456        other      they                    could     live  \n",
       "14457     coolness   between            theirhusbands      NaN  \n",
       "14458          NaN       NaN                      NaN      NaN  \n",
       "\n",
       "[14459 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('input_SenseAndSensibility_10.csv', header=None, sep=',', names=range(10))\n",
    "df\n",
    "\n",
    "#note that this dataset is a sparse dataset, with a relatively high percentage of NaN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7ee203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find out how many unique items are actually in the table:\n",
    "\n",
    "items= set()\n",
    "for col in df:\n",
    "    items.update(df[col].dropna().unique())\n",
    "    \n",
    "#print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72707d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apriori module requires a df of 1s and 0s.  the following code \"one hot encodes\" the data:\n",
    "\n",
    "itemset= set(items)\n",
    "encoded_vals=[]\n",
    "for index, row in df.iterrows():\n",
    "    rowset= set(row)\n",
    "    labels= {}\n",
    "    uncommons= list(itemset-rowset)\n",
    "    commons= list(itemset.intersection(rowset))\n",
    "    for uc in uncommons:\n",
    "        labels[uc] =0\n",
    "    for com in commons:\n",
    "        labels[com]=1\n",
    "    encoded_vals.append(labels)\n",
    "encoded_vals[0]\n",
    "\n",
    "ohe_df=pd.DataFrame(encoded_vals)\n",
    "#ohe_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdfe086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Apriori:\n",
    "#min_support: floating point between 0 and 1 , (# observation with item)/(total observation)\n",
    "\n",
    "freq_items= apriori(ohe_df, min_support=0.003, use_colnames=True, verbose=1)\n",
    "\n",
    "print(freq_items.sort_values(by=\"support\", ascending=False))\n",
    "#freq_items['itemlength']=freq_items['itemsets'].apply(len)\n",
    "#freq_items.query('itemlength == 2').sort_values(by=\"support\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c3f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mining Association Rules\n",
    "#(results show which item is frequently with other items)\n",
    "\n",
    "rules= association_rules(freq_items, metric=\"confidence\", min_threshold=0.8)\n",
    "rules.sort_values(by=\"lift\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "067c61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(rules['support'], rules['confidence'], alpha=0.5)\n",
    "# plt.xlabel('support')\n",
    "# plt.ylabel('confidence')\n",
    "# plt.title('support vs confidence')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03dac303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(rules['support'], rules['lift'], alpha=0.5)\n",
    "# plt.xlabel('support')\n",
    "# plt.ylabel('lift')\n",
    "# plt.title('Support vs Lift')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46b4e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit= np.polyfit(rules['lift'], rules['confidence'], 1)\n",
    "# fit_fn= np.poly1d(fit)\n",
    "# plt.plot(rules['lift'], rules['confidence'], 'yo', rules['lift'],\n",
    "#         fit_fn(rules['lift']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fa881",
   "metadata": {},
   "source": [
    "References:\n",
    "medium article:\n",
    "https://medium.com/analytics-vidhya/association-analysis-in-python-2b955d0180c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
